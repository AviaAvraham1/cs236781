---
title: "Lecture 5: Sequence Models"
header:
    teaser: assets/images/lec5/rnn.png
---

RNN model, input-output sequences relationships, non-sequential input, layered RNN,
backpropagation through time, word embeddings, attention, transformers.

{% include figure image_path="assets/images/lec5/tbptt.png" alt="" caption="" ref="" %}

## Video

{% include video provider="youtube" id="\_mQf44nB4JQ" %}

## Supplementary Video

Word embeddings

{% include video provider="youtube" id="rZSnN5LvvkA" %}

## Slides

{% include ppt_embed.html src="https://onedrive.live.com/embed?cid=449B779EEB6DCD79&amp;resid=449B779EEB6DCD79%21208&amp;authkey=AC2UftXfSCJp_lQ&amp;em=2&amp;wdAr=1.6" %}


## Supplementary Slides

{% include ppt_embed.html
src="https://onedrive.live.com/embed?cid=449B779EEB6DCD79&amp;resid=449B779EEB6DCD79%21299&amp;authkey=AAaQ6kZgZ4vaiiQ&amp;em=2&amp;wdAr=1.7777777777777777" %}


## Lecture Notes

Accompanying notes for this lecture can be found [here]({{ site.baseurl }}{% link _lecture_notes/lecture_05.md %}).
