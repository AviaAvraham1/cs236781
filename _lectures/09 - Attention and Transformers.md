---
title: "Lecture 9: Attention"
header:
---

Attention mechanisem, transformers, self supervised encoder-decoder, LLM
and generative models like GPT

## Video

[Here](https://panoptotech.cloud.panopto.eu/Panopto/Pages/Viewer.aspx?id=fceb6497-75a8-49bd-91c4-af7a00af1bf9)

[Hebew](https://panoptotech.cloud.panopto.eu/Panopto/Pages/Viewer.aspx?id=7bd352e6-5dc5-4fef-8902-b01400a2fa46)


## Slides

[Here](https://github.com/vistalab-technion/cs236781/blob/master/assets/236781_lecture_transformers.pptx)


For this presentation, go to the github via the link below, click "View raw" to download the presentation

[LLMS](https://github.com/vistalab-technion/cs236781/blob/master/assets/236781_LLM.pptx)