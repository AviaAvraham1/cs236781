---
title: "Lecture 7: Transformers"
header:
---

This one is about the Transformer architecture: "attention is all you need" and more.

## Video


## Slides

Can be seen [HERE](https://www.dropbox.com/scl/fi/qfymtmcwnazyb0o7n9xmp/236781_lec8_llm.pptx?rlkey=agjcmura5rgjb3wax7x5isujf&st=q6x8gts7&dl=0)

